{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e372c41-beb6-49c3-a00e-8bd938fa354a",
   "metadata": {},
   "source": [
    "# How to select an objective function using information theory\n",
    "Reproduce figure 3 of the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2c652b-804d-43b0-9bf8-4190f2b8e880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute likelihood\n",
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "import scipy.stats\n",
    "\n",
    "\n",
    "def normal_ll(y, y_hat, transform=None, gradient=1):\n",
    "    '''Log likelihood for the normal distribution with change of variable\n",
    "    \n",
    "    The normal distribution is the formal likelihood for the mean squared error (MSE).\n",
    "    \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y : array_like\n",
    "        Observations.\n",
    "    y_hat : array_like\n",
    "        Predictions.\n",
    "    transform : function\n",
    "        Change of variable transformation.\n",
    "    gradient : function\n",
    "        Gradient of the transform function.\n",
    "        \n",
    "    Proof\n",
    "    -----\n",
    "    https://www.statlect.com/probability-distributions/normal-distribution\n",
    "    '''\n",
    "    if transform is not None:\n",
    "        y = transform(y)\n",
    "        y_hat = transform(y_hat)\n",
    "        \n",
    "    e = y - y_hat\n",
    "    n = len(e)\n",
    "    sigma = e.std()\n",
    "    log_gradient = np.sum(np.log(np.abs(gradient)))\n",
    "    ll = -n * np.log(sigma) - n/2*np.log(2*np.pi) - 1/(2*sigma**2) * (e**2).sum() + log_gradient\n",
    "    return ll\n",
    "\n",
    "\n",
    "def laplace_ll(y, y_hat, transform=None, gradient=1):\n",
    "    '''Log likelihood for Laplace distribution with change of variable\n",
    "    \n",
    "    The laplace distribution is the formal likelihood for the mean absolute\n",
    "    error (MAE).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y : array_like\n",
    "        Observations.\n",
    "    y_hat : array_like\n",
    "        Predictions.\n",
    "    transform : function\n",
    "        Change of variable transformation.\n",
    "    gradient : function\n",
    "        Gradient of the transform function.\n",
    "    '''\n",
    "    if transform is not None:\n",
    "        y = transform(y)\n",
    "        y_hat = transform(y_hat)\n",
    "        \n",
    "    e = (y - y_hat).abs()\n",
    "    n = len(e)\n",
    "    b = e.mean()\n",
    "    log_gradient = np.sum(np.log(np.abs(gradient)))\n",
    "    ll = -n * np.log(2*b) - 1/b * e.sum() + log_gradient\n",
    "    return ll.sum()\n",
    "                                   \n",
    "\n",
    "def msre_ll(y, y_hat):\n",
    "    '''Log likelihood for mean squared square-root error\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y : array_like\n",
    "    y_hat : array_like\n",
    "    '''\n",
    "    return normal_ll(y, y_hat, transform=lambda x: np.sqrt(x), gradient=-1/(2*np.sqrt(y)))\n",
    "\n",
    "\n",
    "def mare_ll(y, y_hat):\n",
    "    '''Log likelihood for mean absolute square-root error\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y : array_like\n",
    "    y_hat : array_like\n",
    "    '''\n",
    "    return laplace_ll(y, y_hat, transform=lambda x: np.sqrt(x), gradient=-1/(2*np.sqrt(y)))\n",
    "\n",
    "\n",
    "def lognormal_ll(y, y_hat):\n",
    "    '''Lognormal log likelihood\n",
    "    \n",
    "    The lognormal distribution is the formal likelihood for the mean squared\n",
    "    log error (MSLE).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y : array_like\n",
    "    y_hat : array_like\n",
    "    '''\n",
    "    return normal_ll(y, y_hat, transform=lambda x: np.log(x), gradient=1/y)\n",
    "\n",
    "\n",
    "def mspe_ll(y, y_hat):\n",
    "    '''Log likelhood for mean squared percentage error\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y : array_like\n",
    "    y_hat : array_like\n",
    "    \n",
    "    '''\n",
    "    return normal_ll(y, y_hat, transform=lambda x: x/y, gradient=-1/(y**2)) \n",
    "\n",
    "\n",
    "def nse_ll(y, y_hat, group='gage_id'):\n",
    "    '''Log likelihood for normalized squared error (NSE)\n",
    "    \n",
    "    NSE is equivalent to the Nash–Sutcliffe model efficiency coefficient.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y : array_like\n",
    "    y_hat : array_like\n",
    "    '''\n",
    "    sigma_o = y.groupby('gage_id').transform(lambda x: x.std())\n",
    "    return normal_ll(y, y_hat, transform=lambda x: x/sigma_o, gradient=1/sigma_o)\n",
    "\n",
    "\n",
    "def loglaplace_ll(y, y_hat):\n",
    "    '''Log likelihood for log Laplace distribution\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y : array_like\n",
    "    y_hat : array_like\n",
    "    '''\n",
    "    return laplace_ll(y, y_hat, transform=lambda x: np.log(x), gradient=1/y)\n",
    "\n",
    "\n",
    "def uniform_ll(y, y_hat):\n",
    "    '''Log likelihood for uniform distribution.\n",
    "    \n",
    "    The uniform log likelihood minimizes the maximum error.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y : array_like\n",
    "    y_hat : array_like\n",
    "    '''\n",
    "    e = np.abs(y - y_hat)\n",
    "    n = len(e)\n",
    "    #ll = -n * np.log(e.max()-e.min()) # standard formulation\n",
    "    ll = -n * np.log(e.max() - 0)\n",
    "    return ll\n",
    "\n",
    "\n",
    "def bernoulli_ll(y, y_hat, groupby=None):\n",
    "    '''TODO and use within zi_ll\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y : array_like\n",
    "    y_hat : array_like\n",
    "    '''\n",
    "    pass\n",
    "\n",
    "\n",
    "\n",
    "def zi_ll(y, y_hat, ll=normal_ll, threshold=0.01, groupby=None):\n",
    "    ''' Zero-inflated log likelihood.\n",
    "    \n",
    "     Parameters\n",
    "    ----------\n",
    "    y : array_like\n",
    "    y_hat : array_like\n",
    "    ll : function\n",
    "        Zero-inflated log likelihood \n",
    "    threshold : float\n",
    "        Value below which is treated as zero\n",
    "    groupby : string\n",
    "        Optional groupby term (testing)\n",
    "    '''\n",
    "    y_o = y <= threshold\n",
    "    y_hat_o = y_hat <= threshold\n",
    "    \n",
    "    if groupby is None:\n",
    "        n1 = (y_o & y_hat_o).sum() # correct zero-flow prediction\n",
    "        n2 = (y_o ^ y_hat_o).sum() # incorrect zero-flow prediction \n",
    "    else:\n",
    "        n1 = (y_o & y_hat_o).groupby(groupby).sum() # correct zero-flow prediction\n",
    "        n2 = (y_o ^ y_hat_o).groupby(groupby).sum() # incorrect zero-flow prediction\n",
    "\n",
    "    n3 = (~y_o & ~y_hat_o) # correct flow predictions\n",
    "    \n",
    "    # fraction of correctly predicted zero flows\n",
    "    rho = np.where( (n1+n2) == 0, 0, n1 / (n1 + n2))\n",
    "    n_rho = 1-rho\n",
    "    \n",
    "    # n1 * np.log(rho) + n2 * np.log(1-rho)\n",
    "    ll_zero = n1[rho!=0] * np.log(rho[rho!=0]) + n2[n_rho!=0]* np.log(n_rho[n_rho!=0])\n",
    "    \n",
    "    return ll_zero.sum() + ll(y[n3], y_hat[n3])\n",
    "\n",
    "\n",
    "def zilognormal_ll(y, y_hat):\n",
    "    '''Log likelihood for zero-inflated lognormal.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y : array_like\n",
    "    y_hat : array_like\n",
    "    '''\n",
    "       \n",
    "    return zi_ll(y, y_hat, ll=lognormal_ll, threshold=0.01)\n",
    "\n",
    "\n",
    "def ziloglaplace_ll(y, y_hat):\n",
    "    '''Log likelihood for zero-inflated laplace.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y : array_like\n",
    "    y_hat : array_like\n",
    "    '''\n",
    "    return zi_ll(y, y_hat, ll=loglaplace_ll, threshold=0.01)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fbc99a9-9a6c-48ff-bfcf-4c5c30b3a04d",
   "metadata": {},
   "source": [
    "Overwrite the nse log likelihood such that we can pass it sigmo_o such that sigma_o is not part of the bootstrap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef72a63-4417-4cb0-beea-260bb1b80c42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def nse_ll(y, y_hat, sigma_o=None, group='gage_id'):\n",
    "    '''Log likelihood for normalized squared error (NSE)\n",
    "    \n",
    "    NSE is equivalent to the Nash–Sutcliffe model efficiency coefficient.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y : array_like\n",
    "    y_hat : array_like\n",
    "    '''\n",
    "    if sigma_o is None:\n",
    "        sigma_o = y.groupby('gage_id').transform(lambda x: x.std(ddof=0))\n",
    "        \n",
    "    return normal_ll(y, y_hat, transform=lambda x: x/sigma_o, gradient=1/sigma_o)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f14e733-9483-4f26-b598-13220bcdebec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read local copy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_parquet('gages2_nndar.parquet')\n",
    "df[df < 0.01] = 0.01\n",
    "\n",
    "sigma_global = df['obs'].groupby('gage_id').transform(lambda x: x.std())\n",
    "\n",
    "\n",
    "# create a convenience function for nse log likelihood that uses the global variance\n",
    "def nse_g(y, y_hat):\n",
    "    return nse_ll(y, y_hat, sigma_o = sigma_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db77639e-476a-48bf-a542-81e097179b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "objectives = {\n",
    "    'U' : {'name':'uniformly distributed error', 'f':uniform_ll},\n",
    "    'MSE' : {'name':'mean squared error', 'f':normal_ll},\n",
    "    'NSE' : {'name':'normalized squared error', 'f':nse_g},\n",
    "    'MAE' : {'name': 'mean absolute error', 'f':laplace_ll},\n",
    "    'MSPE' : {'name': 'mean squared percent error', 'f':mspe_ll},\n",
    "    'MSLE' : {'name':'mean squared log error*', 'f':lognormal_ll},\n",
    "    'MALE' : {'name':'mean absolute log error*', 'f':loglaplace_ll},\n",
    "    'ZMSLE' : {'name':'zero-inflated MSLE', 'f':zilognormal_ll},\n",
    "    'ZMALE' : {'name':'zero-inflated MALE', 'f':ziloglaplace_ll},\n",
    "    'MARE' : {'name':'mean absolute square root error', 'f':mare_ll},\n",
    "}\n",
    "\n",
    "obj_df = pd.DataFrame.from_dict(objectives, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6e99cd-6ea3-4d54-ae80-10b41c145f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# break the bootstrapping into two chunks, in case anything fails\n",
    "output = pd.DataFrame()\n",
    "filename='convergence_bootstrap.csv'\n",
    "\n",
    "# first run\n",
    "columns = ['MSPE','U','MSE','NSE','MAE', 'MSLE','MARE','ZMSLE','MALE','ZMALE']\n",
    "results_dict = {k:[] for k in columns}\n",
    "results_dict['n'] = []\n",
    "\n",
    "#\n",
    "\n",
    "#output.to_csv(filename)\n",
    "\n",
    "for i in range(30, 3000, 10): #10\n",
    "#for i in range(3000, 5000, 10): #10\n",
    "    print(i)\n",
    "    #temp_df = df.groupby('gage_id').head(i)\n",
    "    temp_df = df.groupby('gage_id').sample(i, replace=True, random_state=12345 * i)\n",
    "    sigma_o = sigma_global.groupby('gage_id').head(i)\n",
    "\n",
    "    for index, row in obj_df.iterrows():\n",
    "        results_dict[index].append(- row.f(temp_df['obs'], temp_df['NNDAR'])/ len(temp_df)/ np.log(2))\n",
    "    \n",
    "    results_dict['n'].append(i)\n",
    "\n",
    "    output = pd.DataFrame(data=results_dict)\n",
    "\n",
    "    output.to_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692d9de2-f6ee-451f-a9bb-dd34d65e9769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# second_run\n",
    "output = pd.DataFrame()\n",
    "filename='convergence_bootstrap_2.csv'\n",
    "\n",
    "columns = ['MSPE','U','MSE','NSE','MAE', 'MSLE','MARE','ZMSLE','MALE','ZMALE']\n",
    "results_dict = {k:[] for k in columns}\n",
    "results_dict['n'] = []\n",
    "\n",
    "#\n",
    "\n",
    "#output.to_csv(filename)\n",
    "\n",
    "#for i in range(30, 3000, 10): #10\n",
    "for i in range(3000, 5010, 10): #10\n",
    "    print(i)\n",
    "    #temp_df = df.groupby('gage_id').head(i)\n",
    "    temp_df = df.groupby('gage_id').sample(i, replace=True, random_state=12345 * i)\n",
    "    sigma_o = sigma_global.groupby('gage_id').head(i)\n",
    "\n",
    "    for index, row in obj_df.iterrows():\n",
    "        results_dict[index].append(- row.f(temp_df['obs'], temp_df['NNDAR'])/ len(temp_df)/ np.log(2))\n",
    "    \n",
    "    results_dict['n'].append(i)\n",
    "\n",
    "    output = pd.DataFrame(data=results_dict)\n",
    "\n",
    "    output.to_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33c70d9-bcaa-46bd-bb46-0ba6a8f03146",
   "metadata": {},
   "outputs": [],
   "source": [
    "# join the chunks\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('convergence_bootstrap.csv')\n",
    "df2 = pd.read_csv('convergence_bootstrap_2.csv')\n",
    "\n",
    "df = pd.concat([df, df2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a17460-e7ae-45e8-8139-0dab75c57dbb",
   "metadata": {},
   "source": [
    "## make plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8bbd53e-9479-4e2f-94c5-a6c2444129cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "plt.rc('font', family='serif')\n",
    "plt.rc('xtick', labelsize='x-small')\n",
    "plt.rc('ytick', labelsize='x-small')\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "matplotlib.rcParams['ps.fonttype'] = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035b1296-e11b-4f06-8020-1e5378e66ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['MSPE','U','MSE','NSE','MAE', 'MSLE','MARE','ZMSLE','MALE','ZMALE']\n",
    "columns.append('n')\n",
    "\n",
    "df = df[columns]\n",
    "df = df.set_index('n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f60e112-3863-42d8-9d79-0e8d6764e602",
   "metadata": {},
   "outputs": [],
   "source": [
    "solution = df.tail(5).mean()\n",
    "\n",
    "df_deviations = (df - solution).abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2a7fe4-c03d-47ad-a20a-a4fd579b4b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 5, figsize=(5.51181, 2.7))\n",
    "\n",
    "df_deviations.plot(subplots=True, ls='', marker='.', ax=axes, color=['#af2d46'], markersize=1)\n",
    "\n",
    "\n",
    "for i, ax_r in enumerate(axes):\n",
    "    #ax_r[0].set_ylabel('Divergence in bits')\n",
    "    for ax in ax_r:\n",
    "        leg = ax.legend(frameon=False, loc='upper right', handlelength=0, handletextpad=0, fontsize=8)\n",
    "        for item in leg.legend_handles:\n",
    "            item.set_visible(False)\n",
    "        ax.set_ylim((0,2))\n",
    "        ax.set_xlim((0,5000))\n",
    "        ax.spines[['right', 'top']].set_visible(False)\n",
    "        ax.spines[['bottom','left']].set_position(('outward',5))\n",
    "        #ax.spines[['bottom']].set_position(('outward',5))\n",
    "\n",
    "        ax.get_yaxis().set_ticks([])\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "\n",
    "        if i ==0:\n",
    "            ax.get_xaxis().set_ticks([])\n",
    "            ax.get_xaxis().set_visible(False)\n",
    "\n",
    "        if i==1:\n",
    "            ax.get_xaxis().set_ticks([0,2500,5000])\n",
    "        \n",
    "        ax.set_xlabel(None)\n",
    "        #ax.aspect_ratio('equal')\n",
    "        ax.set_box_aspect(1)\n",
    "\n",
    "\n",
    "axes[1][0].set_ylabel('Absolute error in bits', fontsize=8)\n",
    "axes[1][0].yaxis.set_label_coords(-0.5, 1.45)\n",
    "#axes[1][0].annotate('Absolute error in bits', (0.03,0.5), xycoords='figure fraction', fontsize=8, rotation=90)\n",
    "#axes[1][0].annotate('Sample size (n)', (0.5, 0), xycoords='figure fraction', fontsize=8)\n",
    "axes[1][0].set_xlabel('Sample size (n)', fontsize=8)\n",
    "axes[1][0].xaxis.set_label_coords(3.6, -0.55)\n",
    "\n",
    "axes[1][0].get_yaxis().set_ticks([0,1,2])\n",
    "axes[1][0].get_yaxis().set_visible(True)\n",
    "axes[0][0].get_yaxis().set_ticks([0,1,2])\n",
    "axes[0][0].get_yaxis().set_visible(True)\n",
    "\n",
    "\n",
    "fig.subplots_adjust(wspace=0.5)\n",
    "fig.savefig('figure3.pdf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
